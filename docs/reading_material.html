<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CCAI9012 - Reading Materials</title>
    <link rel="stylesheet" href="docs-style.css">
</head>
<body>
    <div class="container">
        <nav id="sidebar">
            <div class="sidebar-header">
                <h2>CCAI9012</h2>
            </div>
            <ul class="nav-menu">
                <li><a href="index.html">Home</a></li>
                <li><a href="timetable.html">Timetable</a></li>
                <li><a href="installation.html">Installation Guide</a></li>
                <li><a href="starter_kits.html">Starter Kits</a></li>
                <li><a href="reading_material.html" class="active">Reading Materials</a></li>
                <li><a href="datasets.html">Datasets Reference</a></li>
                <li><a href="api/index.html">API Documentation</a></li>
            </ul>
        </nav>

        <main id="content">
<h1>Reading Material</h1>
<h2>Module 1: Foundation</h2>
<ol>
<li>LeCun, Y., Bengio, Y. and Hinton, G. (2015) ‘Deep learning’, _Nature_, 521(7553), pp. 436–444. Available at: [<a href="https://doi.org/10.1038/nature14539">https://doi.org/10.1038/nature14539</a>].  </li>
<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep learning (Chapter 1). MIT Press. <a href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/</a>  </li>
<li>Floridi, L. and Chiriatti, M. (2020) ‘GPT-3: Its Nature, Scope, Limits, and Consequences’, Minds and Machines, 30(4), pp. 681–694. Available at: https://doi.org/10.1007/s11023-020-09548-1.  </li>
</ol>
<h2>Module 2: Understanding AI Risks</h2>
<ol>
<li>Buolamwini, J. and Gebru, T. (2018) ‘Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification’, in Proceedings of the 1st Conference on Fairness, Accountability and Transparency. Conference on Fairness, Accountability and Transparency, PMLR, pp. 77–91. Available at: https://proceedings.mlr.press/v81/buolamwini18a.html   </li>
<li>Lipton, Z.C. (2017) ‘The Mythos of Model Interpretability’. arXiv. Available at: https://doi.org/10.48550/arXiv.1606.03490.  </li>
<li>Gebru, T., Morgenstern, J., Vecchione, B., et al. (2021). Datasheets for datasets. Communications of the ACM, 64(12), 86–92.</li>
</ol>
<h2>Module 3: Responsible AI Integration</h2>
<ol>
<li>Jobin, A., Ienca, M. and Vayena, E. (2019) ‘The global landscape of AI ethics guidelines’, Nature Machine Intelligence, 1(9), pp. 389–399. Available at: https://doi.org/10.1038/s42256-019-0088-2.  </li>
<li>Sutton, R.S., 2019. The bitter lesson. Incomplete Ideas. Available at: <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">http://www.incompleteideas.net/IncIdeas/BitterLesson.html</a>  </li>
<li>Bostrom, N. (2014). Superintelligence: Paths, Dangers, Strategies, Chapter 2: Paths to Superintelligence  </li>
</ol>
        </main>
    </div>
</body>
</html>
