{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0271f6-0d76-4239-ae47-577b9e07c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72866c54-c06b-49b9-aab9-b7e9f74ca092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccai9012 import llm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd0485-1db1-493e-86bb-45065c3130c6",
   "metadata": {},
   "source": [
    "## Initilize and test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0da1b36-95eb-4a14-b39c-e75188a28793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your DEEPSEEK_API_KEY:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "api_key = llm_utils.get_deepseek_api_key()\n",
    "llm = llm_utils.initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0035150c-3c53-488a-a1c1-4a090580018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Prompt:\n",
      "['Is 9.9 or 9.11 bigger?']\n",
      "\n",
      "Let's compare the two numbers: 9.9 and 9.11.\n",
      "\n",
      " be thought of as 9.90 (by adding a zero at the end for easier comparison).\n",
      "9.11 is 9.11.\n",
      "\n",
      ", compare digit by digit from left to right:\n",
      " Both have 9 in the units place.\n",
      "s place (9.9 has 9, and 9.11 has 1). Since 9 > 1, 9.9 is larger.\n",
      "\n",
      "9 is bigger than 9.11**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test connection\n",
    "test = [\"Is 9.9 or 9.11 bigger?\"]\n",
    "llm_utils.ask_llm(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde422f-7563-49b4-b7a9-ce00c4747b5c",
   "metadata": {},
   "source": [
    "## Sparse and embedding the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "691e4f7c-8468-4e49-8297-5b0cba0d0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pdf_retriever(\n",
    "    pdf_path: str,\n",
    "    embedding_model_name: str = \"BAAI/bge-base-en-v1.5\",\n",
    "    chunk_size: int = 1500,\n",
    "    chunk_overlap: int = 200,\n",
    "    top_k: int = 10,\n",
    "    exclude_last_n_pages: int = 2,  # Number of last pages to exclude (e.g., references)\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a PDF, split it into chunks, embed with the specified model, \n",
    "    optionally exclude the last few pages (e.g., references), clean metadata, \n",
    "    and build a FAISS retriever.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF document.\n",
    "        embedding_model_name (str): HuggingFace embedding model name.\n",
    "        chunk_size (int): Maximum characters per chunk.\n",
    "        chunk_overlap (int): Number of overlapping characters between chunks.\n",
    "        top_k (int): Number of top similar chunks to retrieve.\n",
    "        exclude_last_n_pages (int): Number of last pages to exclude from retrieval.\n",
    "\n",
    "    Returns:\n",
    "        retriever: LangChain retriever object for semantic search.\n",
    "    \"\"\"\n",
    "   # Load PDF pages as documents\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "\n",
    "    # Split each page into overlapping chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "\n",
    "    # Clean metadata: keep only 'page' and 'source'\n",
    "    for doc in docs:\n",
    "        doc.metadata = {\n",
    "            \"page\": doc.metadata.get(\"page\"),\n",
    "            \"source\": doc.metadata.get(\"source\")\n",
    "        }\n",
    "\n",
    "    # Exclude the last N pages (e.g., references)\n",
    "    if exclude_last_n_pages > 0:\n",
    "        max_page = max(doc.metadata.get(\"page\", 0) for doc in docs)\n",
    "        docs = [doc for doc in docs if doc.metadata.get(\"page\", 0) <= max_page - exclude_last_n_pages]\n",
    "\n",
    "    # Initialize the embedding model\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "    # Build FAISS vector store from document chunks\n",
    "    vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "\n",
    "    # Create retriever with similarity search\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": top_k}\n",
    "    )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "986f2109-5032-41d4-882e-52882b32d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = build_pdf_retriever(\n",
    "    \"data/1-s2.0-S1353829223001867-main.pdf\",\n",
    "    embedding_model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200,\n",
    "    top_k=8,\n",
    "    exclude_last_n_pages=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "319efc62-6863-4e0e-9ed6-a5f5592b46a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et al., 2011 ; Tonkin and Whitaker, 2019 ; Quinn and Russo, 2022 ). \n",
      "Against this background, there is an urgent need to investigate ways that \n",
      "limited public space resources in cities can be (re-)designed to facilitate \n",
      "more physical and playful activities to make cities more liveable and \n",
      "sustainable ( Edwards et al., 2015 ; Kaczynski et al., 2014 ; Slater et al., \n",
      "2016 ). \n",
      "Currently, studies that examine the relationship between public open \n",
      "space and physical activity mostly focus on the availability of or \n",
      "accessibility to public open space ( Koohsari et al., 2015 ; Lackey and \n",
      "Kaczynski, 2009 ). There are also studies that examine whether the size, \n",
      "density, or the presence of some features in public open space are\n",
      "page: 0\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "the world. It is especially related to the growing trend of Tactical Ur -\n",
      "banism, which aims to create temporary changes using low-cost and \n",
      "moveable features in under-utilized public spaces that leads to long-term \n",
      "impacts ( Jiang et al., 2019 ; Lydon and Garcia, 2015 ; Rossini, 2019; \n",
      "Stevens et al., 2021 ). For instance, the Seating for Socializing (SOS) \n",
      "project in Hong Kong placed 27 32 cm Ã— 32 cm movable meta cubes in a \n",
      "public space. People can decide where to place and how to use the cubes, \n",
      "which help foster the playful use of space and social interaction (Rossini, \n",
      "Fig. 6. Total amount of MET-minutes and trajectory distribution across the day.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "page: 7\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "Health & Place 85 (2024) 103149\n",
      "Available online 10 December 2023\n",
      "1353-8292/Â© 2023 Elsevier Ltd. All rights reserved.\n",
      "Design of public open space: Site features, playing, and physical activity \n",
      "Becky P.Y. Loo\n",
      "a , b\n",
      ", Feiyang Zhang\n",
      "a , * \n",
      "a\n",
      "Department of Geography, University of Hong Kong, Hong Kong, China \n",
      "b\n",
      "School of Geography and Environment, Jiangxi Normal University, Jiangxi, China   \n",
      "ARTICLE INFO  \n",
      "Keywords: \n",
      "Physical activity \n",
      "Play \n",
      "Public space \n",
      "Urban design \n",
      "Deep learning \n",
      "ABSTRACT  \n",
      "Not enough studies have examined how specific design features of public open space, such as movable site \n",
      "features, are associated with people â€™ s physical activity level or playfulness. To fill this gap, this study uses deep\n",
      "page: 0\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "site features ( The Government of the Hong Kong Special Administrative \n",
      "Region, 2020 ). The size of the site is about 0.59 ha. The public space \n",
      "mainly consists of a multipurpose open space located at the centre, a \n",
      "harbourfront walking path, a dog park, as well as a community garden \n",
      "Fig. 1. A flow chart of methodology.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "page: 1\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "Kaczynski, 2009 ). There are also studies that examine whether the size, \n",
      "density, or the presence of some features in public open space are \n",
      "associated with the level of physical activity ( Edwards et al., 2015 ; \n",
      "Kaczynski et al., 2014 ; Koohsari et al., 2015 ; Van Hecke et al., 2018 ). \n",
      "Despite extensive research efforts, there are research gaps that need to \n",
      "be addressed. In particular, whether and to what extent that specific \n",
      "design features of public open space influence physical activity at the \n",
      "microscale are not well examined ( Baek et al., 2015 ; Veitch et al., 2021 ). \n",
      "Regarding play, the Dutch historian Johan Huizinga considered it \n",
      "necessary for the generation of culture. In his book, Homo Ludens , he\n",
      "page: 0\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "Health and Place 85 (2024) 103149\n",
      "6\n",
      "3. Results \n",
      "The Belcher Bay Promenade is a vibrant place where people conduct \n",
      "various types of leisure activities. In total, there were 18592 people \n",
      "observed, with each people having one corresponding trajectory. Based \n",
      "on the criteria listed in the methodology, the trajectories are further \n",
      "classified as â€œ playful â€ (4240), â€œ strolling â€ (2725), â€œ sporty â€ (2119), \n",
      "â€œ passive â€ (3050) and â€œ mixed â€ (6458). It can be seen that the harbour -\n",
      "front open space is an inclusive space that caters for a mix of users with \n",
      "different activities. Fig. 3 shows the spatial and temporal patterns of \n",
      "different trajectory types. It can be observed that there are more tra -\n",
      "jectories during the afternoon of the survey day. More trajectories along\n",
      "page: 5\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "group has also been active during the early afternoon from 1 to 2 PM. \n",
      "4. Discussion \n",
      "4.1. Strengths \n",
      "To our knowledge, this is the first study using people â€™ s movement \n",
      "patterns to identify the playful use of a public space and the associated \n",
      "physical activity level. Compared to traditional methods such as direct \n",
      "observation and questionnaire surveys, we are able to identify playful \n",
      "behaviours in the public space with a large sample size in a much less \n",
      "labour-intensive way and for a continuous period throughout the day. \n",
      "The method has the potential to be applied to other contexts for studying \n",
      "play and physical activity in public open space so that the generaliz -\n",
      "ability of the study results can be increased. \n",
      "The association between site features and the engaging use of the\n",
      "page: 7\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "play and physical activity in public open space so that the generaliz -\n",
      "ability of the study results can be increased. \n",
      "The association between site features and the engaging use of the \n",
      "public open space identified in this study conforms to existing studies \n",
      "that find site features to facilitate playful and active use of the space \n",
      "( Baek et al., 2015 ; Jones, 2013 ). In comparison to the current literature, \n",
      "this study makes unique contributions by identifying that the interaction \n",
      "with semi-fixed/movable features in public space has a stronger asso -\n",
      "ciation with play behaviour, when compared to fixed site features. It is \n",
      "reasonable as semi-fixed/movable features open up more possibilities \n",
      "for people to play in the public space according to their imagination with\n",
      "page: 7\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "results = retriever.get_relevant_documents(\"public space\")\n",
    "for r in results:\n",
    "    print(r.page_content)\n",
    "    print(\"page:\", r.metadata.get(\"page\"))\n",
    "    print(\"source:\", r.metadata.get(\"source\"))\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2ccd0-f116-46a9-b2ae-2be1fb456421",
   "metadata": {},
   "source": [
    "## Summarize the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be74acab-4540-489d-890e-4f6fe3ca0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qa_chain(\n",
    "    query: str,\n",
    "    retriever,\n",
    "    llm,\n",
    "    prompt_template: PromptTemplate = None,\n",
    "    return_sources: bool = False,\n",
    "    save_path: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run a retrieval-based QA chain with optional prompt template, source printing, and saving.\n",
    "\n",
    "    Args:\n",
    "        query (str): The question to ask.\n",
    "        retriever: A retriever object from LangChain.\n",
    "        llm: The LLM to use.\n",
    "        prompt_template (PromptTemplate, optional): Custom prompt template.\n",
    "        return_sources (bool): Whether to print the source documents.\n",
    "        save_path (str, optional): File path to save the result as a .txt file.\n",
    "\n",
    "    Returns:\n",
    "        str: The final result from the QA chain.\n",
    "    \"\"\"\n",
    "    chain_kwargs = {}\n",
    "    if prompt_template is not None:\n",
    "        chain_kwargs[\"prompt\"] = prompt_template\n",
    "\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs=chain_kwargs,\n",
    "        return_source_documents=return_sources,\n",
    "    )\n",
    "\n",
    "    response = qa_chain.invoke(query)\n",
    "\n",
    "    print(\"\\n--- Final Answer ---\")\n",
    "    print(response[\"result\"])\n",
    "\n",
    "    if return_sources:\n",
    "        for i, doc in enumerate(response[\"source_documents\"]):\n",
    "            print(f\"\\n-------------------- Document {i+1} --------------------\")\n",
    "            print(doc.page_content)\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response[\"result\"])\n",
    "        print(f\"\\n Answer saved to: {save_path}\")\n",
    "\n",
    "    return response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a53a4c4-000b-4e23-b17f-ef38220a9301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided context, this paper appears to be a study analyzing physical activity and play behavior in a public open space, likely a waterfront area. The researchers used video data to track visitor trajectories, classifying them into groups (like \"passive\" or \"mixed\") and measuring the associated levels of physical activity (in MET-minutes). The analysis investigates how interactions with specific site features (heart-shaped seating, benches, pavilions, a waterfront) influence activity levels. The discussion acknowledges limitations, including the study's focus on a single day and its inability to capture less active forms of play, and suggests future research should examine multiple sites and different times. The overarching context is a concern about diminishing opportunities for active play, especially for children, due to urbanization and increased screen time.\n",
      "\n",
      "-------------------- Document 1 --------------------\n",
      "*** \n",
      "\u0000 1.956 0.141 (0.100 â€“ 0.201) \n",
      "*** \n",
      "Interaction with heart-shaped \n",
      "seating \n",
      "\u0000 0.116 0.891 (0.827 â€“ 0.96)** 0.020 1.02 (0.959 â€“ 1.085) \u0000 4.720 0.009 (0.004 â€“ 0.019) \n",
      "*** \n",
      "\u0000 0.680 0.507 (0.447 â€“ 0.575) \n",
      "*** \n",
      "Interaction with bench \u0000 0.610 0.543 (0.281 â€“ 1.051) 0.312 1.367 (0.742 â€“ 2.517) \u0000 9.987 0.0 (0.0 â€“ 0.001)*** \u0000 2.589 0.075 (0.033 â€“ 0.172) \n",
      "*** \n",
      "Interaction with pavilion \u0000 0.261 0.77 (0.621 â€“ 0.956)* \u0000 0.914 0.401 (0.222 â€“ 0.723) \n",
      "** \n",
      "\u0000 2.428 0.088 (0.03 â€“ 0.26)*** \u0000 0.587 0.556 (0.411 â€“ 0.754) \n",
      "*** \n",
      "Interaction with waterfront \u0000 2.329 0.097 (0.006 â€“ 1.465) \u0000 1.332 0.264 (0.022 â€“ 3.236) \u0000 1.490 0.225 (0.023 â€“ 2.181) \u0000 0.392 0.676 (0.181 â€“ 2.518) \n",
      "Reference group: Passive (n = 3050).\n",
      "\n",
      "-------------------- Document 2 --------------------\n",
      "E-mail address: feiyang@hku.hk (F. Zhang).  \n",
      "Contents lists available at ScienceDirect \n",
      "Health and Place \n",
      "journal homepag e: www.else vier.com/loc ate/health place \n",
      "https://doi.org/10.1016/j.healthplace.2023.103149 \n",
      "Received 6 July 2023; Received in revised form 7 October 2023; Accepted 21 November 2023\n",
      "\n",
      "-------------------- Document 3 --------------------\n",
      "the ratio of the long to short edge ( R\n",
      "LTS\n",
      ") of the minimum bounding \n",
      "rectangle is calculated for each trajectory, using the following formula: \n",
      "R\n",
      "LTS\n",
      "=\n",
      "L\n",
      "L\n",
      "L\n",
      "S \n",
      "Then, to separate trajectories that only cover small areas with those \n",
      "that explore a larger area in the open space during play, the area of the \n",
      "minimum bounding rectangle is also used. Finally, the total length and \n",
      "Fig. 2. Site map of the study area.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "\n",
      "-------------------- Document 4 --------------------\n",
      "and sheltered environment. In comparison, there are more outdoor \n",
      "activities during Autumn and early Spring when the weather is nice. To \n",
      "test these hypotheses, future studies may consider using video data that \n",
      "covers multiple dates in different months, including weekdays, week -\n",
      "ends, and public holidays, to examine the differences in behavioural \n",
      "patterns at different times. Moreover, future studies may examine public \n",
      "spaces of larger sizes, and compare multiple public spaces using the \n",
      "methods described in this study. \n",
      "Secondly, the proposed study only focuses on physically active play. \n",
      "Less active forms of play, such as playing card/chess and yoga, are not \n",
      "captured in this study. Similarly, the play behaviour of people with\n",
      "\n",
      "-------------------- Document 5 --------------------\n",
      "analysis is also conducted with the Games-Howell test to evaluate \n",
      "pairwise differences among the amount of physical activity for different \n",
      "trajectory groups. Results show that significant differences exist among \n",
      "each pair of the trajectory groups ( p < 0.001), except for between the \n",
      "â€œ passive â€ group and the â€œ mixed â€ group ( p = 0.802). Thus, Hypothesis 3 \n",
      "is supported. \n",
      "Fig. 6 shows the total amount of MET-minutes, as well as the per -\n",
      "centages of different trajectory types throughout the day. Generally, the \n",
      "total number of visitors and total amount of MET-minutes increases in \n",
      "the morning, drops around noon, and peaks around 3:00 â€“ 5:00 p.m. The \n",
      "trend can be partly explained by the thermal comfort level throughout\n",
      "\n",
      "-------------------- Document 6 --------------------\n",
      "of physical activity involved. The average amount of physical activity \n",
      "can also be calculated for each trajectory group. Then, a one-way \n",
      "analysis of variance (ANOVA) is conducted to examine whether there \n",
      "are significant differences in the amount of physical activity among \n",
      "different trajectory groups. \n",
      "Finally, to show the dynamics of physical activity for different tra -\n",
      "jectory groups, we divide the survey period (9:00 a.m. to 6:00 p.m.) into \n",
      "15-min time slots. The number of visitors, percentage of different type of \n",
      "trajectories, total amount of physical activity, and the average amount of \n",
      "physical activity for each trajectory are calculated for each time slot. In \n",
      "rare cases that a trajectory straddles through multiple time slots, it will \n",
      "be counted in all related time slots.\n",
      "\n",
      "-------------------- Document 7 --------------------\n",
      "as video-recording requires special permissions and the original study \n",
      "(conducted by a consultancy firm not related to this research team and \n",
      "commissioned by the Harbourfront Commission) has been completed. \n",
      "More importantly, the site settings have changed since then. We \n",
      "acknowledge that there are daily, monthly, and seasonally differences in \n",
      "the usage of the site. Specifically, there may be fewer visitors during the \n",
      "weekdays compared to weekends. The monthly or seasonable difference \n",
      "will be affected by weather conditions. During hot and rainy summer \n",
      "days (June to August), people may prefer to stay in an air-conditioned \n",
      "and sheltered environment. In comparison, there are more outdoor \n",
      "activities during Autumn and early Spring when the weather is nice. To\n",
      "\n",
      "-------------------- Document 8 --------------------\n",
      "activity in countries around the world ( World Health Organization, \n",
      "2019 ). At the same time, opportunities for children and adolescents to \n",
      "play in public spaces are also diminishing ( Gray, 2011 ; Lee et al., 2021 ; \n",
      "Pyyry and Tani, 2015 ; Vanderbeck et al., 2000 ; Veitch et al., 2006 ), with \n",
      "urbanization ( Lee et al., 2021 ), the popularity of televisions and the \n",
      "Internet ( Gray, 2011 ), and increased parental concerns about children â€™ s \n",
      "safety ( Veitch et al., 2006 ). Active play is essential for people â€™ s \n",
      "well-being, especially for children â€™ s overall development ( Brockman \n",
      "et al., 2011 ; Tonkin and Whitaker, 2019 ; Quinn and Russo, 2022 ). \n",
      "Against this background, there is an urgent need to investigate ways that\n",
      "\n",
      " Answer saved to: output/summary.txt\n"
     ]
    }
   ],
   "source": [
    "summary = run_qa_chain(\n",
    "    query=\"Please summarize the paper in a brief paragraph.\",\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    "    return_sources=True,\n",
    "    save_path=\"output/summary.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da380f1-4fff-422c-9236-28a95165f229",
   "metadata": {},
   "source": [
    "## Ask specific question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49debdf5-40d8-47f1-a577-586735826c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Answer ---\n",
      "The paper applies a **multinomial logistic regression** model. \n",
      "\n",
      "Specifically:\n",
      "- The **dependent variable** is the type of trajectory (e.g., passive, serious, playful, mixed).\n",
      "- The **independent variables** include the total duration within 0.5m distance to different types of features (e.g., heart-shaped seating, bench, pavilion, waterfront), which indicate the level of interaction between people and these features.\n",
      "- The **reference group** for the regression is the \"Passive\" trajectory type (with n=3050 observations).\n",
      "\n",
      "This model is used to determine whether different movement trajectories are associated with the usage of different spatial features.\n",
      "\n",
      "-------------------- Document 1 --------------------\n",
      "*** \n",
      "\u0000 1.956 0.141 (0.100 â€“ 0.201) \n",
      "*** \n",
      "Interaction with heart-shaped \n",
      "seating \n",
      "\u0000 0.116 0.891 (0.827 â€“ 0.96)** 0.020 1.02 (0.959 â€“ 1.085) \u0000 4.720 0.009 (0.004 â€“ 0.019) \n",
      "*** \n",
      "\u0000 0.680 0.507 (0.447 â€“ 0.575) \n",
      "*** \n",
      "Interaction with bench \u0000 0.610 0.543 (0.281 â€“ 1.051) 0.312 1.367 (0.742 â€“ 2.517) \u0000 9.987 0.0 (0.0 â€“ 0.001)*** \u0000 2.589 0.075 (0.033 â€“ 0.172) \n",
      "*** \n",
      "Interaction with pavilion \u0000 0.261 0.77 (0.621 â€“ 0.956)* \u0000 0.914 0.401 (0.222 â€“ 0.723) \n",
      "** \n",
      "\u0000 2.428 0.088 (0.03 â€“ 0.26)*** \u0000 0.587 0.556 (0.411 â€“ 0.754) \n",
      "*** \n",
      "Interaction with waterfront \u0000 2.329 0.097 (0.006 â€“ 1.465) \u0000 1.332 0.264 (0.022 â€“ 3.236) \u0000 1.490 0.225 (0.023 â€“ 2.181) \u0000 0.392 0.676 (0.181 â€“ 2.518) \n",
      "Reference group: Passive (n = 3050).\n",
      "\n",
      "-------------------- Document 2 --------------------\n",
      "frames ( Loo and Fan, 2023 ). The same homography matrix calculated in \n",
      "the last step is also used to project the pixel coordinates into \n",
      "geographical coordinates. \n",
      "In order to find out whether different movement trajectories are \n",
      "associated with the usage of different features in space, a multinomial \n",
      "logistic regression is used. Specifically, the type of trajectory is consid -\n",
      "ered as the dependent variable. For independent variables, the total \n",
      "duration within 0.5m distance to different types of features is used to \n",
      "indicate the level of interaction between people and features. People \n",
      "with passive trajectories are used as the reference group. \n",
      "Table 1 \n",
      "Thresholds for different trajectory types.\n",
      "\n",
      "-------------------- Document 3 --------------------\n",
      "E-mail address: feiyang@hku.hk (F. Zhang).  \n",
      "Contents lists available at ScienceDirect \n",
      "Health and Place \n",
      "journal homepag e: www.else vier.com/loc ate/health place \n",
      "https://doi.org/10.1016/j.healthplace.2023.103149 \n",
      "Received 6 July 2023; Received in revised form 7 October 2023; Accepted 21 November 2023\n",
      "\n",
      "-------------------- Document 4 --------------------\n",
      "behaviour the person is conducting. For instance, Yan and Forsyth \n",
      "(2005) used people â€™ s trajectories to study their â€œ wandering â€ behaviour \n",
      "in public spaces and their spatial relationship with the surrounding \n",
      "landscape features, such as the water fountain. Similarly, Okamoto et al. \n",
      "(2011) used movement trajectories to classify behaviours into â€œ going \n",
      "straight â€ , â€œ finding the way â€ , and â€œ walking around â€ . In a more recent \n",
      "study, the complexity and diversity of human trajectories are used to \n",
      "measure the vitality of public spaces ( Niu et al., 2022 ). \n",
      "Based on our initial site observations and hand drawing of people â€™ s \n",
      "trajectories, we found that the observed trajectories can actually \n",
      "distinguish people who move through space with a sense of seriousness\n",
      "\n",
      "-------------------- Document 5 --------------------\n",
      "Health and Place 85 (2024) 103149\n",
      "5\n",
      "2.4. Trajectories and physical activity \n",
      "In this study, we also estimate the intensity of physical activity in the \n",
      "unit of metabolic equivalent of task (MET) ( Maher and Conroy, 2015 ) \n",
      "using people â€™ s movement speed ( Silva et al., 2015 ). Upon manually \n",
      "checking the videos, this approach is appropriate for this study as few \n",
      "people were found to be conducting stationary exercises, such as yoga or \n",
      "Tai Chi, during the survey period. Generally, the total energy expendi -\n",
      "ture of a person is calculated by multiplying the duration (minutes) of a \n",
      "specific activity and the estimated MET to derive the total amount of \n",
      "MET-minutes ( Maher and Conroy, 2015 ). \n",
      "Based on the Physical Activity Guidelines for Americans ( U.S. Depart -\n",
      "\n",
      "-------------------- Document 6 --------------------\n",
      "In order to calculate the total amount of physical activity (in MET- \n",
      "minutes), the duration of stay should also be considered. It is impor -\n",
      "tant to note that there is always a systematic underestimation for the \n",
      "duration of stay due to the tracking issue in occluded scenes, which is \n",
      "common in current pedestrian tracking algorithms ( Stadler and Beyerer, \n",
      "2021 ; Zhang et al., 2022 ). The corresponding physical activity intensity \n",
      "levels (light, moderate, vigorous) and mean METs (2.25, 4.5, 7.75) are \n",
      "derived based on each individual â€™ s movement speed. Next, the total \n",
      "MET-minutes for a trajectory are calculated by summing up the amount \n",
      "of physical activity involved. The average amount of physical activity \n",
      "can also be calculated for each trajectory group. Then, a one-way\n",
      "\n",
      "-------------------- Document 7 --------------------\n",
      "the ratio of the long to short edge ( R\n",
      "LTS\n",
      ") of the minimum bounding \n",
      "rectangle is calculated for each trajectory, using the following formula: \n",
      "R\n",
      "LTS\n",
      "=\n",
      "L\n",
      "L\n",
      "L\n",
      "S \n",
      "Then, to separate trajectories that only cover small areas with those \n",
      "that explore a larger area in the open space during play, the area of the \n",
      "minimum bounding rectangle is also used. Finally, the total length and \n",
      "Fig. 2. Site map of the study area.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "\n",
      "-------------------- Document 8 --------------------\n",
      "trajectories with time duration, but will need to be tackled in future \n",
      "research. \n",
      "Fourthly, there can be some ambiguity between different trajectory \n",
      "types. For example, a trajectory can be classified as â€œ playful â€ or â€œ mixed â€ \n",
      "depending on the specific thresholds set. Future studies may explore \n",
      "alternative ways of clustering people â€™ s movement patterns, such as using \n",
      "Fig. 7. Average MET-minutes by trajectory type across the day.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "\n",
      " Answer saved to: output/question.txt\n"
     ]
    }
   ],
   "source": [
    "answer = run_qa_chain(\n",
    "    query=\"What model is applied in the paper?\",\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    "    return_sources=True,\n",
    "    save_path=\"output/question.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15606c24-d8b8-4feb-8e71-c386760c83b6",
   "metadata": {},
   "source": [
    "## Extract information form multiple papers for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d33d34a0-cd60-4b31-85be-b08942f29994",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Given the following document text, extract key information for a concise literature review. \n",
    "Output a markdown table with columns:\n",
    "\n",
    "| Problem | Research Gap | Methodology | Key Results |\n",
    "|-------|--------------|-------------|-------------|\n",
    "\n",
    "Requirements:\n",
    "- Each paper must be represented in a single row.\n",
    "- If a category contains multiple points, separate them using \"; \".\n",
    "- Do NOT create multiple rows for the same paper.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9ec97c6-ded8-445c-8959-0818cabb778c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/1-s2.0-S1353829223001867-main.pdf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 624 0 (offset 0)\n",
      "Ignoring wrong pointing object 625 0 (offset 0)\n",
      "Ignoring wrong pointing object 628 0 (offset 0)\n",
      "Ignoring wrong pointing object 629 0 (offset 0)\n",
      "Ignoring wrong pointing object 663 0 (offset 0)\n",
      "Ignoring wrong pointing object 664 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided text, the paper appears to be by Loo, B.P.Y. and Zhang, F. (2024) in *Health and Place*, Vol. 85, 103149. The study analyzes human movement trajectories in a public open space (Belcher's Bay Promenade, Hong Kong) to understand playful behavior and its relationship with site features and physical activity.\n",
      "\n",
      "| Problem | Research Gap | Methodology | Key Results |\n",
      "| :--- | :--- | :--- | :--- |\n",
      "| Difficulty in measuring and distinguishing playful behavior from other activities in public open spaces. | Few studies use movement trajectories to detect playful activities; existing research often focuses on classifying general movement (e.g., \"going straight\") rather than play specifically. | Analysis of anonymized video data to generate pedestrian trajectories; trajectories classified into types (Playful, Strolling, Sporty, Passive, Mixed) using indicators (detour ratio, area & ratio of min. bounding rectangle, length, duration); multinomial logistic regression to link trajectory types to interaction with site features; physical activity (MET-minutes) estimated from speed. | Different trajectory types are significantly associated with interaction durations of different site features (heart-shaped seating, bench, pavilion, waterfront); trajectory types show significant differences in the amount and intensity of physical activity (as shown in Fig. 5). |\n",
      "Processing data/DeepSOCIAL.pdf ...\n",
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided text, here is the extracted key information for a concise literature review.\n",
      "\n",
      "| Problem | Research Gap | Methodology | Key Results |\n",
      "| :--- | :--- | :--- | :--- |\n",
      "| Accurate and real-time object detection for applications like social distancing monitoring. | Need for robust detectors that handle occlusions, overlaps, and crowded scenes in real-world public places; Defining appropriate weights for long-term risk heat map averaging. | Proposes a YOLO-based object detection model fine-tuned on human categories from the Google Open Images dataset; Evaluated on the challenging Oxford Town Centre (OTC) dataset; System includes object detection, tracking, and a red-zone prediction algorithm for risk assessment. | The developed system successfully generates 2D and 3D violation and risk heat maps; It identifies crowded zones where social distancing is breached with a high level of confidence and accuracy; Performance is benchmarked on Precision, Recall, and FPS metrics against state-of-the-art methods. |\n",
      "| Evolution of object detection models for improved speed and accuracy. | Transitioning from two-stage (region proposal-based) detectors to single-stage (unified) real-time detectors. | Various methodologies are summarized, including: Two-stage (R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN); Single-stage (YOLO series, SSD, RetinaNet); Various backbones (VGG, ResNet, Darknet, CSPNet); Various necks (SPP, FPN, PAN, BiFPN). | The table provides a comprehensive list of state-of-the-art design options for CNN-based object detection models, covering input augmentation, activation functions, backbone architectures, neck modules, regularization techniques, and detection heads (both anchor-based and anchor-free). |\n",
      "Processing data/Monitoring COVID-19 social distancing.pdf ...\n",
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided text, here is the extracted information for a concise literature review.\n",
      "\n",
      "| Problem | Research Gap | Methodology | Key Results |\n",
      "| :--- | :--- | :--- | :--- |\n",
      "| Monitoring social distancing in real-time via automated object detection and tracking. | Higher number of false positives may cause discomfort/panic; Privacy and individual rights concerns are not adequately addressed. | A framework using fine-tuned object detection models (Faster R-CNN, SSD, YOLOv3) on a dataset from Open Images and Oxford Town Center footage. People are tracked and grouped using a 3D feature space (x, y, d) and pairwise L2 norm distance. A violation index (people/groups) is calculated. | Inception v2 was identified as the most efficient backbone architecture (highest accuracy/parameter ratio). The fine-tuned models were evaluated using mAP and loss metrics. The proposed framework successfully identified social groups and calculated a violation index for monitoring. |\n",
      "Processing data/Small public space vitality analysis and evaluation.pdf ...\n",
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided text, here is the key information extracted for a concise literature review.\n",
      "\n",
      "| Problem | Research Gap | Methodology | Key Results |\n",
      "| :--- | :--- | :--- | :--- |\n",
      "| Quantifying the multifaceted concept of \"vitality\" in small public spaces is complex and lacks a systematic, high-precision data-driven framework. | Existing methods for large-scale spaces are difficult to transform for small public spaces due to low data accuracy; a more systematic representation system based on high-precision data is needed. | A computer vision-based framework to extract human trajectories from videos and calculate five quantitative indicators (number of people, duration of stay, motion speed, trajectory diversity, trajectory complexity); Stepwise multiple linear regression was used to model the relationship between these indicators and subjective expert ratings of overall vitality. | A significant multiple linear regression model was constructed (N=48, RÂ²=.781, p<.001); The number of people (num), duration of stay (dur), trajectory diversity (TD), and trajectory complexity (TC) were all statistically significant predictors (p<.05) of overall vitality. |\n",
      "\n",
      " Saved results to output/multiple_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "folder_path = \"data\"\n",
    "save_csv_path = \"output/multiple_comparison.csv\"\n",
    "query_text = \"Extract key information from this paper.\"\n",
    "results = []\n",
    "\n",
    "for fname in sorted(os.listdir(folder_path)):\n",
    "    if not fname.lower().endswith(\".pdf\"):\n",
    "        continue\n",
    "    pdf_path = os.path.join(folder_path, fname)\n",
    "    print(f\"Processing {pdf_path} ...\")\n",
    "\n",
    "    # Build retriever for this pdf\n",
    "    retriever = build_pdf_retriever(pdf_path)\n",
    "\n",
    "    # Run QA chain for structured extraction\n",
    "    extracted_text = run_qa_chain(\n",
    "        query=query_text,\n",
    "        retriever=retriever,\n",
    "        llm=llm,\n",
    "        prompt_template=structured_prompt,\n",
    "        return_sources=False\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"pdf_path\": fname,\n",
    "        \"extracted_text\": extracted_text,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "os.makedirs(os.path.dirname(save_csv_path), exist_ok=True)\n",
    "df.to_csv(save_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n Saved results to {save_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84405323-7078-40a7-b157-797db2d6c733",
   "metadata": {},
   "source": [
    "## Combine the result extracted from the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ec0deb8-7ef0-4a92-8630-1f60134cc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "def parse_markdown_table(md_text: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse a markdown table from a string, merging all rows into a single row.\n",
    "    Multiple points in any column are separated by '; '.\n",
    "    Suitable when Problem/Topic itself may have multiple entries.\n",
    "    \"\"\"\n",
    "    # Extract markdown table lines\n",
    "    table_lines = [line for line in md_text.splitlines() if line.strip().startswith(\"|\")]\n",
    "\n",
    "    if len(table_lines) < 2:\n",
    "        raise ValueError(\"No valid markdown table found.\")\n",
    "\n",
    "    # Extract column names\n",
    "    header_line = table_lines[0]\n",
    "    column_names = [col.strip() for col in header_line.strip().strip('|').split('|')]\n",
    "\n",
    "    # Initialize a dict to accumulate content\n",
    "    merged_data = {col: [] for col in column_names}\n",
    "\n",
    "    # Iterate over all rows (skip header + separator)\n",
    "    for line in table_lines[2:]:\n",
    "        cells = [re.sub(r'<br\\s*/?>', '; ', cell.strip(), flags=re.IGNORECASE)\n",
    "                 for cell in line.strip().strip('|').split('|')]\n",
    "        # Pad cells if needed\n",
    "        while len(cells) < len(column_names):\n",
    "            cells.append(\"\")\n",
    "\n",
    "        # Append each cell to the corresponding column list\n",
    "        for i, col in enumerate(column_names):\n",
    "            if cells[i] and cells[i] != \"N/A\":\n",
    "                merged_data[col].append(cells[i])\n",
    "\n",
    "    # Join multiple entries per column with \"; \"\n",
    "    merged_row = {col: \"; \".join(merged_data[col]) if merged_data[col] else \"N/A\"\n",
    "                  for col in column_names}\n",
    "\n",
    "    # Convert to single-row DataFrame\n",
    "    df = pd.DataFrame([merged_row])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6cbec3b-ae96-485f-ba51-ee1dedeb4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_list = []\n",
    "\n",
    "for i, md in enumerate(df[\"extracted_text\"]):\n",
    "    try:\n",
    "        parsed = parse_markdown_table(md)\n",
    "        parsed[\"source_doc\"] = df.loc[i, \"pdf_path\"] if \"pdf_path\" in df.columns else f\"doc_{i+1}\"\n",
    "        merged_df_list.append(parsed)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse doc {i+1}: {e}\")\n",
    "\n",
    "final_df = pd.concat(merged_df_list, ignore_index=True)\n",
    "final_df.to_csv(\"output/merged_lit_review.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cab1b22-6ed6-468e-9847-33f6ee5a22a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Research Gap</th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Key Results</th>\n",
       "      <th>source_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difficulty in measuring and distinguishing pla...</td>\n",
       "      <td>Few studies use movement trajectories to detec...</td>\n",
       "      <td>Analysis of anonymized video data to generate ...</td>\n",
       "      <td>Different trajectory types are significantly a...</td>\n",
       "      <td>1-s2.0-S1353829223001867-main.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accurate and real-time object detection for ap...</td>\n",
       "      <td>Need for robust detectors that handle occlusio...</td>\n",
       "      <td>Proposes a YOLO-based object detection model f...</td>\n",
       "      <td>The developed system successfully generates 2D...</td>\n",
       "      <td>DeepSOCIAL.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monitoring social distancing in real-time via ...</td>\n",
       "      <td>Higher number of false positives may cause dis...</td>\n",
       "      <td>A framework using fine-tuned object detection ...</td>\n",
       "      <td>Inception v2 was identified as the most effici...</td>\n",
       "      <td>Monitoring COVID-19 social distancing.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quantifying the multifaceted concept of \"vital...</td>\n",
       "      <td>Existing methods for large-scale spaces are di...</td>\n",
       "      <td>A computer vision-based framework to extract h...</td>\n",
       "      <td>A significant multiple linear regression model...</td>\n",
       "      <td>Small public space vitality analysis and evalu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Problem  \\\n",
       "0  Difficulty in measuring and distinguishing pla...   \n",
       "1  Accurate and real-time object detection for ap...   \n",
       "2  Monitoring social distancing in real-time via ...   \n",
       "3  Quantifying the multifaceted concept of \"vital...   \n",
       "\n",
       "                                        Research Gap  \\\n",
       "0  Few studies use movement trajectories to detec...   \n",
       "1  Need for robust detectors that handle occlusio...   \n",
       "2  Higher number of false positives may cause dis...   \n",
       "3  Existing methods for large-scale spaces are di...   \n",
       "\n",
       "                                         Methodology  \\\n",
       "0  Analysis of anonymized video data to generate ...   \n",
       "1  Proposes a YOLO-based object detection model f...   \n",
       "2  A framework using fine-tuned object detection ...   \n",
       "3  A computer vision-based framework to extract h...   \n",
       "\n",
       "                                         Key Results  \\\n",
       "0  Different trajectory types are significantly a...   \n",
       "1  The developed system successfully generates 2D...   \n",
       "2  Inception v2 was identified as the most effici...   \n",
       "3  A significant multiple linear regression model...   \n",
       "\n",
       "                                          source_doc  \n",
       "0                  1-s2.0-S1353829223001867-main.pdf  \n",
       "1                                     DeepSOCIAL.pdf  \n",
       "2          Monitoring COVID-19 social distancing.pdf  \n",
       "3  Small public space vitality analysis and evalu...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
