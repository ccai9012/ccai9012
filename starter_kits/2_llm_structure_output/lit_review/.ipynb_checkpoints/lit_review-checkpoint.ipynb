{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c0271f6-0d76-4239-ae47-577b9e07c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72866c54-c06b-49b9-aab9-b7e9f74ca092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccai9012 import llm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd0485-1db1-493e-86bb-45065c3130c6",
   "metadata": {},
   "source": [
    "## Initilize and test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0da1b36-95eb-4a14-b39c-e75188a28793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your DEEPSEEK_API_KEY:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "api_key = llm_utils.get_deepseek_api_key()\n",
    "llm = llm_utils.initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0035150c-3c53-488a-a1c1-4a090580018c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Prompt:\n",
      "['Is 9.9 or 9.11 bigger?']\n",
      "\n",
      "Let's compare the two numbers: **9.9** and **9.11**.\n",
      "\n",
      "---\n",
      "\n",
      "**Step 1: Compare the whole number part**  \n",
      "Both numbers have the same whole number part: **9**.\n",
      "\n",
      "---\n",
      "\n",
      "**Step 2: Compare the decimal part**  \n",
      "- **9.9** means \\( 9 + \\frac{9}{10} \\) = 9.900...  \n",
      "- **9.11** means \\( 9 + \\frac{11}{100} \\) = 9.11  \n",
      "\n",
      "---\n",
      "\n",
      "**Step 3: Align decimal places for clarity**  \n",
      "Write both with the same number of decimal places:  \n",
      "- 9.90  \n",
      "- 9.11  \n",
      "\n",
      "Now compare digit by digit after the decimal:  \n",
      "- Tenths place: 9 (first number) vs 1 (second number)  \n",
      "- Since 9 > 1, **9.9 is larger**.\n",
      "\n",
      "---\n",
      "\n",
      "\\[\n",
      "\\boxed{9.9}\n",
      "\\]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test connection\n",
    "test = [\"Is 9.9 or 9.11 bigger?\"]\n",
    "llm_utils.ask_llm(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde422f-7563-49b4-b7a9-ce00c4747b5c",
   "metadata": {},
   "source": [
    "## Sparse and embedding the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986f2109-5032-41d4-882e-52882b32d019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanxuanhe/Document/250421_AI_course/toolkit/ccai9012/llm_utils.py:392: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n"
     ]
    }
   ],
   "source": [
    "retriever = llm_utils.build_pdf_retriever(\n",
    "    pdf_path=\"data/1-s2.0-S1353829223001867-main.pdf\",\n",
    "    embedding_model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200,\n",
    "    top_k=8,\n",
    "    exclude_last_n_pages=2 # exlude the last few Reference pages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319efc62-6863-4e0e-9ed6-a5f5592b46a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/cjcx_y2d6h1gpmvcb422p0pr0000gn/T/ipykernel_52971/161525779.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(\"public space\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et al., 2011 ; Tonkin and Whitaker, 2019 ; Quinn and Russo, 2022 ). \n",
      "Against this background, there is an urgent need to investigate ways that \n",
      "limited public space resources in cities can be (re-)designed to facilitate \n",
      "more physical and playful activities to make cities more liveable and \n",
      "sustainable ( Edwards et al., 2015 ; Kaczynski et al., 2014 ; Slater et al., \n",
      "2016 ). \n",
      "Currently, studies that examine the relationship between public open \n",
      "space and physical activity mostly focus on the availability of or \n",
      "accessibility to public open space ( Koohsari et al., 2015 ; Lackey and \n",
      "Kaczynski, 2009 ). There are also studies that examine whether the size, \n",
      "density, or the presence of some features in public open space are\n",
      "page: 0\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "the world. It is especially related to the growing trend of Tactical Ur -\n",
      "banism, which aims to create temporary changes using low-cost and \n",
      "moveable features in under-utilized public spaces that leads to long-term \n",
      "impacts ( Jiang et al., 2019 ; Lydon and Garcia, 2015 ; Rossini, 2019; \n",
      "Stevens et al., 2021 ). For instance, the Seating for Socializing (SOS) \n",
      "project in Hong Kong placed 27 32 cm √ó 32 cm movable meta cubes in a \n",
      "public space. People can decide where to place and how to use the cubes, \n",
      "which help foster the playful use of space and social interaction (Rossini, \n",
      "Fig. 6. Total amount of MET-minutes and trajectory distribution across the day.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "page: 7\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "Health & Place 85 (2024) 103149\n",
      "Available online 10 December 2023\n",
      "1353-8292/¬© 2023 Elsevier Ltd. All rights reserved.\n",
      "Design of public open space: Site features, playing, and physical activity \n",
      "Becky P.Y. Loo\n",
      "a , b\n",
      ", Feiyang Zhang\n",
      "a , * \n",
      "a\n",
      "Department of Geography, University of Hong Kong, Hong Kong, China \n",
      "b\n",
      "School of Geography and Environment, Jiangxi Normal University, Jiangxi, China   \n",
      "ARTICLE INFO  \n",
      "Keywords: \n",
      "Physical activity \n",
      "Play \n",
      "Public space \n",
      "Urban design \n",
      "Deep learning \n",
      "ABSTRACT  \n",
      "Not enough studies have examined how specific design features of public open space, such as movable site \n",
      "features, are associated with people ‚Äô s physical activity level or playfulness. To fill this gap, this study uses deep\n",
      "page: 0\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "site features ( The Government of the Hong Kong Special Administrative \n",
      "Region, 2020 ). The size of the site is about 0.59 ha. The public space \n",
      "mainly consists of a multipurpose open space located at the centre, a \n",
      "harbourfront walking path, a dog park, as well as a community garden \n",
      "Fig. 1. A flow chart of methodology.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "page: 1\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "Kaczynski, 2009 ). There are also studies that examine whether the size, \n",
      "density, or the presence of some features in public open space are \n",
      "associated with the level of physical activity ( Edwards et al., 2015 ; \n",
      "Kaczynski et al., 2014 ; Koohsari et al., 2015 ; Van Hecke et al., 2018 ). \n",
      "Despite extensive research efforts, there are research gaps that need to \n",
      "be addressed. In particular, whether and to what extent that specific \n",
      "design features of public open space influence physical activity at the \n",
      "microscale are not well examined ( Baek et al., 2015 ; Veitch et al., 2021 ). \n",
      "Regarding play, the Dutch historian Johan Huizinga considered it \n",
      "necessary for the generation of culture. In his book, Homo Ludens , he\n",
      "page: 0\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "Health and Place 85 (2024) 103149\n",
      "6\n",
      "3. Results \n",
      "The Belcher Bay Promenade is a vibrant place where people conduct \n",
      "various types of leisure activities. In total, there were 18592 people \n",
      "observed, with each people having one corresponding trajectory. Based \n",
      "on the criteria listed in the methodology, the trajectories are further \n",
      "classified as ‚Äú playful ‚Äù (4240), ‚Äú strolling ‚Äù (2725), ‚Äú sporty ‚Äù (2119), \n",
      "‚Äú passive ‚Äù (3050) and ‚Äú mixed ‚Äù (6458). It can be seen that the harbour -\n",
      "front open space is an inclusive space that caters for a mix of users with \n",
      "different activities. Fig. 3 shows the spatial and temporal patterns of \n",
      "different trajectory types. It can be observed that there are more tra -\n",
      "jectories during the afternoon of the survey day. More trajectories along\n",
      "page: 5\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "group has also been active during the early afternoon from 1 to 2 PM. \n",
      "4. Discussion \n",
      "4.1. Strengths \n",
      "To our knowledge, this is the first study using people ‚Äô s movement \n",
      "patterns to identify the playful use of a public space and the associated \n",
      "physical activity level. Compared to traditional methods such as direct \n",
      "observation and questionnaire surveys, we are able to identify playful \n",
      "behaviours in the public space with a large sample size in a much less \n",
      "labour-intensive way and for a continuous period throughout the day. \n",
      "The method has the potential to be applied to other contexts for studying \n",
      "play and physical activity in public open space so that the generaliz -\n",
      "ability of the study results can be increased. \n",
      "The association between site features and the engaging use of the\n",
      "page: 7\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n",
      "play and physical activity in public open space so that the generaliz -\n",
      "ability of the study results can be increased. \n",
      "The association between site features and the engaging use of the \n",
      "public open space identified in this study conforms to existing studies \n",
      "that find site features to facilitate playful and active use of the space \n",
      "( Baek et al., 2015 ; Jones, 2013 ). In comparison to the current literature, \n",
      "this study makes unique contributions by identifying that the interaction \n",
      "with semi-fixed/movable features in public space has a stronger asso -\n",
      "ciation with play behaviour, when compared to fixed site features. It is \n",
      "reasonable as semi-fixed/movable features open up more possibilities \n",
      "for people to play in the public space according to their imagination with\n",
      "page: 7\n",
      "source: data/1-s2.0-S1353829223001867-main.pdf\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Find related chunks from the paper\n",
    "results = retriever.get_relevant_documents(\"public space\")\n",
    "for r in results:\n",
    "    print(r.page_content)\n",
    "    print(\"page:\", r.metadata.get(\"page\"))\n",
    "    print(\"source:\", r.metadata.get(\"source\"))\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2ccd0-f116-46a9-b2ae-2be1fb456421",
   "metadata": {},
   "source": [
    "## Summarize the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a53a4c4-000b-4e23-b17f-ef38220a9301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided context, I cannot provide a complete summary of the paper.\n",
      "\n",
      "The excerpts contain specific data from a results section (including statistical values and odds ratios) and parts of the discussion and limitations sections. The paper appears to be a study analyzing physical activity and play behavior (using trajectory analysis) in a public open space, specifically a waterfront area.\n",
      "\n",
      "However, the context does not include the paper's abstract, introduction, or a clear statement of its main objectives and conclusions, which are necessary for a proper summary. The authors acknowledge limitations such as the study being based on a single day's video data and not capturing less active forms of play.\n",
      "\n",
      "-------------------- Document 1 --------------------\n",
      "*** \n",
      "\u0000 1.956 0.141 (0.100 ‚Äì 0.201) \n",
      "*** \n",
      "Interaction with heart-shaped \n",
      "seating \n",
      "\u0000 0.116 0.891 (0.827 ‚Äì 0.96)** 0.020 1.02 (0.959 ‚Äì 1.085) \u0000 4.720 0.009 (0.004 ‚Äì 0.019) \n",
      "*** \n",
      "\u0000 0.680 0.507 (0.447 ‚Äì 0.575) \n",
      "*** \n",
      "Interaction with bench \u0000 0.610 0.543 (0.281 ‚Äì 1.051) 0.312 1.367 (0.742 ‚Äì 2.517) \u0000 9.987 0.0 (0.0 ‚Äì 0.001)*** \u0000 2.589 0.075 (0.033 ‚Äì 0.172) \n",
      "*** \n",
      "Interaction with pavilion \u0000 0.261 0.77 (0.621 ‚Äì 0.956)* \u0000 0.914 0.401 (0.222 ‚Äì 0.723) \n",
      "** \n",
      "\u0000 2.428 0.088 (0.03 ‚Äì 0.26)*** \u0000 0.587 0.556 (0.411 ‚Äì 0.754) \n",
      "*** \n",
      "Interaction with waterfront \u0000 2.329 0.097 (0.006 ‚Äì 1.465) \u0000 1.332 0.264 (0.022 ‚Äì 3.236) \u0000 1.490 0.225 (0.023 ‚Äì 2.181) \u0000 0.392 0.676 (0.181 ‚Äì 2.518) \n",
      "Reference group: Passive (n = 3050).\n",
      "\n",
      "-------------------- Document 2 --------------------\n",
      "E-mail address: feiyang@hku.hk (F. Zhang).  \n",
      "Contents lists available at ScienceDirect \n",
      "Health and Place \n",
      "journal homepag e: www.else vier.com/loc ate/health place \n",
      "https://doi.org/10.1016/j.healthplace.2023.103149 \n",
      "Received 6 July 2023; Received in revised form 7 October 2023; Accepted 21 November 2023\n",
      "\n",
      "-------------------- Document 3 --------------------\n",
      "the ratio of the long to short edge ( R\n",
      "LTS\n",
      ") of the minimum bounding \n",
      "rectangle is calculated for each trajectory, using the following formula: \n",
      "R\n",
      "LTS\n",
      "=\n",
      "L\n",
      "L\n",
      "L\n",
      "S \n",
      "Then, to separate trajectories that only cover small areas with those \n",
      "that explore a larger area in the open space during play, the area of the \n",
      "minimum bounding rectangle is also used. Finally, the total length and \n",
      "Fig. 2. Site map of the study area.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "\n",
      "-------------------- Document 4 --------------------\n",
      "and sheltered environment. In comparison, there are more outdoor \n",
      "activities during Autumn and early Spring when the weather is nice. To \n",
      "test these hypotheses, future studies may consider using video data that \n",
      "covers multiple dates in different months, including weekdays, week -\n",
      "ends, and public holidays, to examine the differences in behavioural \n",
      "patterns at different times. Moreover, future studies may examine public \n",
      "spaces of larger sizes, and compare multiple public spaces using the \n",
      "methods described in this study. \n",
      "Secondly, the proposed study only focuses on physically active play. \n",
      "Less active forms of play, such as playing card/chess and yoga, are not \n",
      "captured in this study. Similarly, the play behaviour of people with\n",
      "\n",
      "-------------------- Document 5 --------------------\n",
      "analysis is also conducted with the Games-Howell test to evaluate \n",
      "pairwise differences among the amount of physical activity for different \n",
      "trajectory groups. Results show that significant differences exist among \n",
      "each pair of the trajectory groups ( p < 0.001), except for between the \n",
      "‚Äú passive ‚Äù group and the ‚Äú mixed ‚Äù group ( p = 0.802). Thus, Hypothesis 3 \n",
      "is supported. \n",
      "Fig. 6 shows the total amount of MET-minutes, as well as the per -\n",
      "centages of different trajectory types throughout the day. Generally, the \n",
      "total number of visitors and total amount of MET-minutes increases in \n",
      "the morning, drops around noon, and peaks around 3:00 ‚Äì 5:00 p.m. The \n",
      "trend can be partly explained by the thermal comfort level throughout\n",
      "\n",
      "-------------------- Document 6 --------------------\n",
      "of physical activity involved. The average amount of physical activity \n",
      "can also be calculated for each trajectory group. Then, a one-way \n",
      "analysis of variance (ANOVA) is conducted to examine whether there \n",
      "are significant differences in the amount of physical activity among \n",
      "different trajectory groups. \n",
      "Finally, to show the dynamics of physical activity for different tra -\n",
      "jectory groups, we divide the survey period (9:00 a.m. to 6:00 p.m.) into \n",
      "15-min time slots. The number of visitors, percentage of different type of \n",
      "trajectories, total amount of physical activity, and the average amount of \n",
      "physical activity for each trajectory are calculated for each time slot. In \n",
      "rare cases that a trajectory straddles through multiple time slots, it will \n",
      "be counted in all related time slots.\n",
      "\n",
      "-------------------- Document 7 --------------------\n",
      "as video-recording requires special permissions and the original study \n",
      "(conducted by a consultancy firm not related to this research team and \n",
      "commissioned by the Harbourfront Commission) has been completed. \n",
      "More importantly, the site settings have changed since then. We \n",
      "acknowledge that there are daily, monthly, and seasonally differences in \n",
      "the usage of the site. Specifically, there may be fewer visitors during the \n",
      "weekdays compared to weekends. The monthly or seasonable difference \n",
      "will be affected by weather conditions. During hot and rainy summer \n",
      "days (June to August), people may prefer to stay in an air-conditioned \n",
      "and sheltered environment. In comparison, there are more outdoor \n",
      "activities during Autumn and early Spring when the weather is nice. To\n",
      "\n",
      "-------------------- Document 8 --------------------\n",
      "activity in countries around the world ( World Health Organization, \n",
      "2019 ). At the same time, opportunities for children and adolescents to \n",
      "play in public spaces are also diminishing ( Gray, 2011 ; Lee et al., 2021 ; \n",
      "Pyyry and Tani, 2015 ; Vanderbeck et al., 2000 ; Veitch et al., 2006 ), with \n",
      "urbanization ( Lee et al., 2021 ), the popularity of televisions and the \n",
      "Internet ( Gray, 2011 ), and increased parental concerns about children ‚Äô s \n",
      "safety ( Veitch et al., 2006 ). Active play is essential for people ‚Äô s \n",
      "well-being, especially for children ‚Äô s overall development ( Brockman \n",
      "et al., 2011 ; Tonkin and Whitaker, 2019 ; Quinn and Russo, 2022 ). \n",
      "Against this background, there is an urgent need to investigate ways that\n",
      "\n",
      " Answer saved to: output/summary.txt\n"
     ]
    }
   ],
   "source": [
    "summary = llm_utils.run_qa_chain(\n",
    "    query=\"Please summarize the paper in a brief paragraph.\",\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    "    return_sources=True,\n",
    "    save_path=\"output/summary.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da380f1-4fff-422c-9236-28a95165f229",
   "metadata": {},
   "source": [
    "## Ask specific question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49debdf5-40d8-47f1-a577-586735826c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided context, the paper applies a **multinomial logistic regression** model. \n",
      "\n",
      "The purpose of this model is to determine whether different movement trajectories are associated with the usage of different features in space.\n",
      "\n",
      "Specifically:\n",
      "*   **Dependent variable:** The type of trajectory (e.g., passive, playful, etc.).\n",
      "*   **Independent variables:** The total duration a person spends within 0.5 meters of different types of spatial features.\n",
      "*   **Reference group:** People with passive trajectories are used as the baseline for comparison.\n",
      "\n",
      "-------------------- Document 1 --------------------\n",
      "*** \n",
      "\u0000 1.956 0.141 (0.100 ‚Äì 0.201) \n",
      "*** \n",
      "Interaction with heart-shaped \n",
      "seating \n",
      "\u0000 0.116 0.891 (0.827 ‚Äì 0.96)** 0.020 1.02 (0.959 ‚Äì 1.085) \u0000 4.720 0.009 (0.004 ‚Äì 0.019) \n",
      "*** \n",
      "\u0000 0.680 0.507 (0.447 ‚Äì 0.575) \n",
      "*** \n",
      "Interaction with bench \u0000 0.610 0.543 (0.281 ‚Äì 1.051) 0.312 1.367 (0.742 ‚Äì 2.517) \u0000 9.987 0.0 (0.0 ‚Äì 0.001)*** \u0000 2.589 0.075 (0.033 ‚Äì 0.172) \n",
      "*** \n",
      "Interaction with pavilion \u0000 0.261 0.77 (0.621 ‚Äì 0.956)* \u0000 0.914 0.401 (0.222 ‚Äì 0.723) \n",
      "** \n",
      "\u0000 2.428 0.088 (0.03 ‚Äì 0.26)*** \u0000 0.587 0.556 (0.411 ‚Äì 0.754) \n",
      "*** \n",
      "Interaction with waterfront \u0000 2.329 0.097 (0.006 ‚Äì 1.465) \u0000 1.332 0.264 (0.022 ‚Äì 3.236) \u0000 1.490 0.225 (0.023 ‚Äì 2.181) \u0000 0.392 0.676 (0.181 ‚Äì 2.518) \n",
      "Reference group: Passive (n = 3050).\n",
      "\n",
      "-------------------- Document 2 --------------------\n",
      "frames ( Loo and Fan, 2023 ). The same homography matrix calculated in \n",
      "the last step is also used to project the pixel coordinates into \n",
      "geographical coordinates. \n",
      "In order to find out whether different movement trajectories are \n",
      "associated with the usage of different features in space, a multinomial \n",
      "logistic regression is used. Specifically, the type of trajectory is consid -\n",
      "ered as the dependent variable. For independent variables, the total \n",
      "duration within 0.5m distance to different types of features is used to \n",
      "indicate the level of interaction between people and features. People \n",
      "with passive trajectories are used as the reference group. \n",
      "Table 1 \n",
      "Thresholds for different trajectory types.\n",
      "\n",
      "-------------------- Document 3 --------------------\n",
      "E-mail address: feiyang@hku.hk (F. Zhang).  \n",
      "Contents lists available at ScienceDirect \n",
      "Health and Place \n",
      "journal homepag e: www.else vier.com/loc ate/health place \n",
      "https://doi.org/10.1016/j.healthplace.2023.103149 \n",
      "Received 6 July 2023; Received in revised form 7 October 2023; Accepted 21 November 2023\n",
      "\n",
      "-------------------- Document 4 --------------------\n",
      "behaviour the person is conducting. For instance, Yan and Forsyth \n",
      "(2005) used people ‚Äô s trajectories to study their ‚Äú wandering ‚Äù behaviour \n",
      "in public spaces and their spatial relationship with the surrounding \n",
      "landscape features, such as the water fountain. Similarly, Okamoto et al. \n",
      "(2011) used movement trajectories to classify behaviours into ‚Äú going \n",
      "straight ‚Äù , ‚Äú finding the way ‚Äù , and ‚Äú walking around ‚Äù . In a more recent \n",
      "study, the complexity and diversity of human trajectories are used to \n",
      "measure the vitality of public spaces ( Niu et al., 2022 ). \n",
      "Based on our initial site observations and hand drawing of people ‚Äô s \n",
      "trajectories, we found that the observed trajectories can actually \n",
      "distinguish people who move through space with a sense of seriousness\n",
      "\n",
      "-------------------- Document 5 --------------------\n",
      "Health and Place 85 (2024) 103149\n",
      "5\n",
      "2.4. Trajectories and physical activity \n",
      "In this study, we also estimate the intensity of physical activity in the \n",
      "unit of metabolic equivalent of task (MET) ( Maher and Conroy, 2015 ) \n",
      "using people ‚Äô s movement speed ( Silva et al., 2015 ). Upon manually \n",
      "checking the videos, this approach is appropriate for this study as few \n",
      "people were found to be conducting stationary exercises, such as yoga or \n",
      "Tai Chi, during the survey period. Generally, the total energy expendi -\n",
      "ture of a person is calculated by multiplying the duration (minutes) of a \n",
      "specific activity and the estimated MET to derive the total amount of \n",
      "MET-minutes ( Maher and Conroy, 2015 ). \n",
      "Based on the Physical Activity Guidelines for Americans ( U.S. Depart -\n",
      "\n",
      "-------------------- Document 6 --------------------\n",
      "In order to calculate the total amount of physical activity (in MET- \n",
      "minutes), the duration of stay should also be considered. It is impor -\n",
      "tant to note that there is always a systematic underestimation for the \n",
      "duration of stay due to the tracking issue in occluded scenes, which is \n",
      "common in current pedestrian tracking algorithms ( Stadler and Beyerer, \n",
      "2021 ; Zhang et al., 2022 ). The corresponding physical activity intensity \n",
      "levels (light, moderate, vigorous) and mean METs (2.25, 4.5, 7.75) are \n",
      "derived based on each individual ‚Äô s movement speed. Next, the total \n",
      "MET-minutes for a trajectory are calculated by summing up the amount \n",
      "of physical activity involved. The average amount of physical activity \n",
      "can also be calculated for each trajectory group. Then, a one-way\n",
      "\n",
      "-------------------- Document 7 --------------------\n",
      "the ratio of the long to short edge ( R\n",
      "LTS\n",
      ") of the minimum bounding \n",
      "rectangle is calculated for each trajectory, using the following formula: \n",
      "R\n",
      "LTS\n",
      "=\n",
      "L\n",
      "L\n",
      "L\n",
      "S \n",
      "Then, to separate trajectories that only cover small areas with those \n",
      "that explore a larger area in the open space during play, the area of the \n",
      "minimum bounding rectangle is also used. Finally, the total length and \n",
      "Fig. 2. Site map of the study area.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "\n",
      "-------------------- Document 8 --------------------\n",
      "trajectories with time duration, but will need to be tackled in future \n",
      "research. \n",
      "Fourthly, there can be some ambiguity between different trajectory \n",
      "types. For example, a trajectory can be classified as ‚Äú playful ‚Äù or ‚Äú mixed ‚Äù \n",
      "depending on the specific thresholds set. Future studies may explore \n",
      "alternative ways of clustering people ‚Äô s movement patterns, such as using \n",
      "Fig. 7. Average MET-minutes by trajectory type across the day.  \n",
      "B.P.Y. Loo and F. Zhang\n",
      "\n",
      " Answer saved to: output/question.txt\n"
     ]
    }
   ],
   "source": [
    "answer = llm_utils.run_qa_chain(\n",
    "    query=\"What model is applied in the paper?\",\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    "    return_sources=True,\n",
    "    save_path=\"output/question.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15606c24-d8b8-4feb-8e71-c386760c83b6",
   "metadata": {},
   "source": [
    "## Extract information form multiple papers for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33d34a0-cd60-4b31-85be-b08942f29994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "structured_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Given the following document text, extract key information for a concise literature review. \n",
    "Output a markdown table with columns:\n",
    "\n",
    "| Problem | Research Gap | Methodology | Key Results |\n",
    "|-------|--------------|-------------|-------------|\n",
    "\n",
    "Requirements:\n",
    "- Each paper must be represented in a single row.\n",
    "- If a category contains multiple points, separate them using \"; \".\n",
    "- Do NOT create multiple rows for the same paper.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9ec97c6-ded8-445c-8959-0818cabb778c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/1-s2.0-S1353829223001867-main.pdf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 624 0 (offset 0)\n",
      "Ignoring wrong pointing object 625 0 (offset 0)\n",
      "Ignoring wrong pointing object 628 0 (offset 0)\n",
      "Ignoring wrong pointing object 629 0 (offset 0)\n",
      "Ignoring wrong pointing object 663 0 (offset 0)\n",
      "Ignoring wrong pointing object 664 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided text, here is the key information extracted for a concise literature review.\n",
      "\n",
      "| Problem | Research Gap | Methodology | Key Results |\n",
      "|-------|--------------|-------------|-------------|\n",
      "| Difficulty in measuring and distinguishing playful activities from other behaviors in public open spaces; need to understand how movement patterns relate to space usage and physical activity. | Few studies measure play directly; existing research often overlooks the relationship between specific movement trajectories, interaction with site features, and resulting physical activity levels in unprogrammed public spaces. | Analysis of anonymized video data from a harbourfront space; generation of pedestrian trajectories tracked for ‚â•25s; classification into types (Playful, Strolling, Sporty, Passive, Mixed) using indicators (detour ratio, bounding box area/ratio, trajectory length/duration); multinomial logistic regression to link trajectory types to feature interaction; estimation of physical activity (MET-minutes) from speed. | Playful trajectories are associated with interaction with specific site features (heart-shaped seating, benches, pavilion); different trajectory types exhibit significantly different levels of physical activity (Sporty trajectories have the highest MET-minutes); the method successfully uses movement trajectories to classify behavior and measure play and physical activity in a public space. |\n",
      "Processing data/DeepSOCIAL.pdf ...\n",
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided text, here is a concise literature review in the requested format.\n",
      "\n",
      "| Problem | Research Gap | Methodology | Key Results |\n",
      "|-------|--------------|-------------|-------------|\n",
      "| Developing a vision-based system for monitoring social distancing and assessing critical density/risk of infection spread, particularly for COVID-19. | How to define appropriate averaging weights and coefficients for long-term risk heat maps (crowd maps); Normalization of risk maps over time. | An AI and Computer Vision methodology involving a CNN-based object detection model (fine-tuned on human categories from Google Open Images) for people detection, followed by tracking and a red-zone prediction algorithm to generate 2D/3D violation and risk heat maps. | The system successfully identified crowded zones with social distancing breaches and areas with minimal risk on the Oxford Town Centre (OTC) dataset; The proposed method is feasible for social distancing monitoring and risk assessment with high confidence and accuracy. |\n",
      "| Achieving optimal speed and accuracy for real-time object detection. | Improving upon previous object detection architectures for better performance. | Proposes YOLOv4, a CNN-based object detector with an optimized architecture focusing on input augmentations, backbone feature extraction, neck design, and head prediction. | YOLOv4 is presented as achieving state-of-the-art optimal speed and accuracy for object detection. |\n",
      "| Enabling real-time object detection with a unified, single-stage model. | Overcoming the complexity and speed limitations of two-stage detectors (e.g., R-CNN series). | Proposes YOLO (You Only Look Once), a unified architecture that frames object detection as a single regression problem to spatially separated bounding boxes and class probabilities. | YOLO enables real-time, unified object detection. |\n",
      "| Improving the speed and performance of two-stage object detectors. | The computational bottleneck of generating region proposals in Fast R-CNN. | Introduces Faster R-CNN, which uses a Region Proposal Network (RPN) to generate proposals directly from the feature map, sharing convolutional features with the detection network. | Enables real-time object detection with a region proposal network; Towards real-time performance. |\n",
      "| Addressing class imbalance in dense object detection. | The class imbalance problem encountered during training of one-stage detectors, where easy negative examples dominate the loss. | Proposes RetinaNet and a novel Focal Loss function that applies a modulating term to the cross entropy loss to focus learning on hard negative examples. | Focal loss enables one-stage detectors to achieve accuracy comparable to state-of-the-art two-stage detectors. |\n",
      "Processing data/Monitoring COVID-19 social distancing.pdf ...\n",
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided text, here is the key information extracted for a concise literature review.\n",
      "\n",
      "| Problem | Research Gap | Methodology | Key Results |\n",
      "| :--- | :--- | :--- | :--- |\n",
      "| Monitoring social distancing in public spaces via surveillance footage. | The need for an efficient, real-time framework that balances accuracy and speed for practical deployment; addressing privacy concerns and higher false positives. | A deep learning framework combining fine-tuned object detection models (Faster RCNN, SSD, YOLO v3) with a tracking algorithm. Uses anchor boxes for detection and Mahalanobis/cosine distance for tracking. Social groups are identified using L2 norm on a 3D feature space (x, y, d). | Models were trained on a filtered \"Person\" class dataset from Open Images; Inception v2 was identified as an efficient backbone for Faster RCNN/SSD due to its high accuracy-to-parameters ratio; the framework outputs color-coded groups and a violation index (people/groups). |\n",
      "Processing data/Small public space vitality analysis and evaluation.pdf ...\n",
      "\n",
      "--- Final Answer ---\n",
      "Based on the provided text, here is the key information extracted for a concise literature review.\n",
      "\n",
      "| Problem | Research Gap | Methodology | Key Results |\n",
      "| :--- | :--- | :--- | :--- |\n",
      "| Quantifying the vitality of small public spaces in a systematic and human-oriented way. | Existing methods (e.g., for large-scale spaces) have low data accuracy for small public spaces; a need for a high-precision, multifaceted vitality representation system. | A computer vision-based framework to extract human trajectories from videos and calculate five quantitative indicators (number of people, duration of stay, motion speed, trajectory diversity, trajectory complexity); Stepwise multiple linear regression to model the relationship between indicators and expert-rated overall vitality scores. | A significant regression model was found (N=48, R¬≤=.781, p<.001). Key predictors of vitality were: number of people (Œ≤=.582, p<.001); duration of stay (Œ≤=.254, p=.001); trajectory diversity (Œ≤=.307, p=.004); trajectory complexity (Œ≤=.159, p=.034). Motion speed was not a significant predictor in the final model. |\n",
      "\n",
      " Saved results to output/multiple_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"data\"\n",
    "save_csv_path = \"output/multiple_comparison.csv\"\n",
    "query_text = \"Extract key information from this paper.\"\n",
    "results = []\n",
    "\n",
    "for fname in sorted(os.listdir(folder_path)):\n",
    "    if not fname.lower().endswith(\".pdf\"):\n",
    "        continue\n",
    "    pdf_path = os.path.join(folder_path, fname)\n",
    "    print(f\"Processing {pdf_path} ...\")\n",
    "\n",
    "    # Build retriever for this pdf\n",
    "    retriever = llm_utils.build_pdf_retriever(pdf_path)\n",
    "\n",
    "    # Run QA chain for structured extraction\n",
    "    extracted_text = llm_utils.run_qa_chain(\n",
    "        query=query_text,\n",
    "        retriever=retriever,\n",
    "        llm=llm,\n",
    "        prompt_template=structured_prompt,\n",
    "        return_sources=False\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"pdf_path\": fname,\n",
    "        \"extracted_text\": extracted_text,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "os.makedirs(os.path.dirname(save_csv_path), exist_ok=True)\n",
    "df.to_csv(save_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n Saved results to {save_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84405323-7078-40a7-b157-797db2d6c733",
   "metadata": {},
   "source": [
    "## Combine the result extracted from the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6cbec3b-ae96-485f-ba51-ee1dedeb4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_list = []\n",
    "\n",
    "for i, md in enumerate(df[\"extracted_text\"]):\n",
    "    try:\n",
    "        parsed = llm_utils.parse_markdown_table(md)\n",
    "        parsed[\"source_doc\"] = df.loc[i, \"pdf_path\"] if \"pdf_path\" in df.columns else f\"doc_{i+1}\"\n",
    "        merged_df_list.append(parsed)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse doc {i+1}: {e}\")\n",
    "\n",
    "final_df = pd.concat(merged_df_list, ignore_index=True)\n",
    "final_df.to_csv(\"output/merged_lit_review.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cab1b22-6ed6-468e-9847-33f6ee5a22a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Research Gap</th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Key Results</th>\n",
       "      <th>source_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difficulty in measuring and distinguishing pla...</td>\n",
       "      <td>Few studies measure play directly; existing re...</td>\n",
       "      <td>Analysis of anonymized video data from a harbo...</td>\n",
       "      <td>Playful trajectories are associated with inter...</td>\n",
       "      <td>1-s2.0-S1353829223001867-main.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Developing a vision-based system for monitorin...</td>\n",
       "      <td>How to define appropriate averaging weights an...</td>\n",
       "      <td>An AI and Computer Vision methodology involvin...</td>\n",
       "      <td>The system successfully identified crowded zon...</td>\n",
       "      <td>DeepSOCIAL.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Achieving optimal speed and accuracy for real-...</td>\n",
       "      <td>Improving upon previous object detection archi...</td>\n",
       "      <td>Proposes YOLOv4, a CNN-based object detector w...</td>\n",
       "      <td>YOLOv4 is presented as achieving state-of-the-...</td>\n",
       "      <td>DeepSOCIAL.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enabling real-time object detection with a uni...</td>\n",
       "      <td>Overcoming the complexity and speed limitation...</td>\n",
       "      <td>Proposes YOLO (You Only Look Once), a unified ...</td>\n",
       "      <td>YOLO enables real-time, unified object detection.</td>\n",
       "      <td>DeepSOCIAL.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Improving the speed and performance of two-sta...</td>\n",
       "      <td>The computational bottleneck of generating reg...</td>\n",
       "      <td>Introduces Faster R-CNN, which uses a Region P...</td>\n",
       "      <td>Enables real-time object detection with a regi...</td>\n",
       "      <td>DeepSOCIAL.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Addressing class imbalance in dense object det...</td>\n",
       "      <td>The class imbalance problem encountered during...</td>\n",
       "      <td>Proposes RetinaNet and a novel Focal Loss func...</td>\n",
       "      <td>Focal loss enables one-stage detectors to achi...</td>\n",
       "      <td>DeepSOCIAL.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Monitoring social distancing in public spaces ...</td>\n",
       "      <td>The need for an efficient, real-time framework...</td>\n",
       "      <td>A deep learning framework combining fine-tuned...</td>\n",
       "      <td>Models were trained on a filtered \"Person\" cla...</td>\n",
       "      <td>Monitoring COVID-19 social distancing.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Quantifying the vitality of small public space...</td>\n",
       "      <td>Existing methods (e.g., for large-scale spaces...</td>\n",
       "      <td>A computer vision-based framework to extract h...</td>\n",
       "      <td>A significant regression model was found (N=48...</td>\n",
       "      <td>Small public space vitality analysis and evalu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Problem  \\\n",
       "0  Difficulty in measuring and distinguishing pla...   \n",
       "1  Developing a vision-based system for monitorin...   \n",
       "2  Achieving optimal speed and accuracy for real-...   \n",
       "3  Enabling real-time object detection with a uni...   \n",
       "4  Improving the speed and performance of two-sta...   \n",
       "5  Addressing class imbalance in dense object det...   \n",
       "6  Monitoring social distancing in public spaces ...   \n",
       "7  Quantifying the vitality of small public space...   \n",
       "\n",
       "                                        Research Gap  \\\n",
       "0  Few studies measure play directly; existing re...   \n",
       "1  How to define appropriate averaging weights an...   \n",
       "2  Improving upon previous object detection archi...   \n",
       "3  Overcoming the complexity and speed limitation...   \n",
       "4  The computational bottleneck of generating reg...   \n",
       "5  The class imbalance problem encountered during...   \n",
       "6  The need for an efficient, real-time framework...   \n",
       "7  Existing methods (e.g., for large-scale spaces...   \n",
       "\n",
       "                                         Methodology  \\\n",
       "0  Analysis of anonymized video data from a harbo...   \n",
       "1  An AI and Computer Vision methodology involvin...   \n",
       "2  Proposes YOLOv4, a CNN-based object detector w...   \n",
       "3  Proposes YOLO (You Only Look Once), a unified ...   \n",
       "4  Introduces Faster R-CNN, which uses a Region P...   \n",
       "5  Proposes RetinaNet and a novel Focal Loss func...   \n",
       "6  A deep learning framework combining fine-tuned...   \n",
       "7  A computer vision-based framework to extract h...   \n",
       "\n",
       "                                         Key Results  \\\n",
       "0  Playful trajectories are associated with inter...   \n",
       "1  The system successfully identified crowded zon...   \n",
       "2  YOLOv4 is presented as achieving state-of-the-...   \n",
       "3  YOLO enables real-time, unified object detection.   \n",
       "4  Enables real-time object detection with a regi...   \n",
       "5  Focal loss enables one-stage detectors to achi...   \n",
       "6  Models were trained on a filtered \"Person\" cla...   \n",
       "7  A significant regression model was found (N=48...   \n",
       "\n",
       "                                          source_doc  \n",
       "0                  1-s2.0-S1353829223001867-main.pdf  \n",
       "1                                     DeepSOCIAL.pdf  \n",
       "2                                     DeepSOCIAL.pdf  \n",
       "3                                     DeepSOCIAL.pdf  \n",
       "4                                     DeepSOCIAL.pdf  \n",
       "5                                     DeepSOCIAL.pdf  \n",
       "6          Monitoring COVID-19 social distancing.pdf  \n",
       "7  Small public space vitality analysis and evalu...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
